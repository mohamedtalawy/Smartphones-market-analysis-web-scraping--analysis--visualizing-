{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7ef652",
   "metadata": {},
   "source": [
    "### 1- Importing the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b14bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import string\n",
    "from itertools import zip_longest\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055e315",
   "metadata": {},
   "source": [
    "### 2- Identifing the used lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e139a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[]\n",
    "Models= []\n",
    "Prices=[]\n",
    "Description=[]\n",
    "links=[]\n",
    "colors=[]\n",
    "rams=[]\n",
    "storages=[]\n",
    "fulfillings=[]\n",
    "batteries=[]\n",
    "screen_sizes=[]\n",
    "ratings=[]\n",
    "rating_avgs=[]\n",
    "elements=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378efe1",
   "metadata": {},
   "source": [
    "### 3- Scraping the pages with filters in SOUQ.com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5204f349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 has been scrolled down\n",
      "Page 2 has been scrolled down\n",
      "Page 3 has been scrolled down\n",
      "Page 4 has been scrolled down\n",
      "Page 5 has been scrolled down\n",
      "Page 6 has been scrolled down\n",
      "Page 7 has been scrolled down\n",
      "Page 8 has been scrolled down\n",
      "Page 9 has been scrolled down\n",
      "Page 10 has been scrolled down\n"
     ]
    }
   ],
   "source": [
    "# Tell Selenium to get the URL we're interested in.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Scraping multiple pages\n",
    "for x in range(10):\n",
    "# Throw your source into BeautifulSoup and start parsing!\n",
    "    result= driver.get(f'https://egypt.souq.com/eg-en/mobile-phone/apple%7Csamsung%7Cxiaomi%7Coppo%7Chuawei/smartphone/a-7-1870/l/?_=1628070328225&section=2&page={x+1}')\n",
    "    timeout = 5\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.ID, 'element_id'))\n",
    "        WebDriverWait(driver, timeout).until(element_present)\n",
    "    except TimeoutException:\n",
    "        print(f\"Page {x+1} has been scrolled down\")\n",
    "    source_data = driver.page_source\n",
    "    soup = bs(source_data)\n",
    "# scraping the model and the price of the phones from the main page\n",
    "    Model= soup.find_all(\"h1\" , {\"class\":\"itemTitle\"})\n",
    "    L= soup.find_all(\"div\" , {\"class\":\"col col-info item-content\"})\n",
    "    Price= soup.find_all(\"h3\" , {\"class\":\"itemPrice\"})\n",
    "    fulfilling= soup.find_all(\"span\" , {\"class\":\"free-shipping fs-ab-black\"})    \n",
    "# Filling the lists with the cleaned elements\n",
    "    for i in range(len(Model)):\n",
    "        brands.append(Model[i].text.strip().split(' ')[0])\n",
    "        Prices.append(Price[i].text.strip().replace(\"EGP\", \"\"))\n",
    "        Description.append(Model[i].text.strip())\n",
    "        links.append(L[i].find(\"a\").attrs['href'])\n",
    "        try:        \n",
    "            fulfillings.append(fulfilling[i].text.strip())\n",
    "        except :\n",
    "            fulfillings.append(\"Paid Shipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42bff1",
   "metadata": {},
   "source": [
    "### 4- Exctracting more details from the inner page in each phone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae15eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "\n",
    "    result= driver.get(link)\n",
    "    source_data = driver.page_source\n",
    "    search = driver.find_element_by_xpath('//a[@class=\"expand readmore specs\"]')\n",
    "    search.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try: \n",
    "        try:\n",
    "            color= driver.find_element_by_xpath('//div[@class=\"level-1 item-connection\"and @data-toggle=\"colors-drop\"]/span')\n",
    "        except :\n",
    "            color= driver.find_element_by_xpath('//div[@class=\"connection-stand\"]/div/div/div[@class=\"item-connection text-center active\"]/a')\n",
    "\n",
    "        colors.append(color.text.strip())\n",
    "    except:\n",
    "        colors.append(\"None\")\n",
    "    \n",
    "    try:        \n",
    "        ram= driver.find_element_by_xpath('//div[@class=\"connection-stand\"]/div/div[@id=\"rams_en\"]/div[@class=\"item-connection text-center active\"]/a')\n",
    "        rams.append(ram.text.replace(\"GB\", \"\").strip())\n",
    "    except :\n",
    "        ram= \"None\"\n",
    "        rams.append(ram)\n",
    "    try:      \n",
    "        storage= driver.find_element_by_xpath('//div[@class=\"connection-stand\"]/div/div[@id=\"storage_capacity_en\"]/div[@class=\"item-connection text-center active\"]/a')\n",
    "        storages.append(storage.text.replace(\"GB\", \"\").strip())\n",
    "    except :\n",
    "        storage= \"None\"   \n",
    "        storages.append(storage)\n",
    "    try:\n",
    "        try:        \n",
    "            battery= driver.find_element_by_xpath('//dd[contains(text(),\"mA\")]')\n",
    "        except :\n",
    "            battery= driver.find_element_by_xpath('//dd[contains(text(),\"milliampere_hour\")]')\n",
    "        batteries.append(battery.text.replace(\"mAH\", \"\").replace(\"mAh\", \"\").replace(\"milliampere_hour\", \"\").strip())\n",
    "    except:\n",
    "        batteries.append(\"None\")\n",
    "    \n",
    "    try:  \n",
    "        try:\n",
    "            screen_size= driver.find_element_by_xpath('//dd[contains(text(),\"inch\")]')\n",
    "        except:        \n",
    "            screen_size= driver.find_element_by_xpath('//dd[contains(text(),\"Inch\")]') \n",
    "\n",
    "        screen_sizes.append(screen_size.text.replace(\"inches\", \"\").replace(\"Inch\", \"\").strip())\n",
    "    except:\n",
    "        screen_sizes.append(\"None\")\n",
    "    try:\n",
    "        rating_avg= driver.find_element_by_xpath('//div[@class=\"grouped-list\"]/div/div/div[@class=\"product-rating clearfix clearPadding-v-small\"]/div[@class=\"large-4 small-12 columns\"]/div/div[@class=\"hide-for-small-only\"]/div/strong')\n",
    "        rating_avgs.append(rating_avg.text.strip())\n",
    "    except:\n",
    "        rating_avg= \"None\" \n",
    "        rating_avgs.append(rating_avg)\n",
    "    try:\n",
    "        rating= driver.find_element_by_xpath('//span[contains(text(),\"ratings\")]')\n",
    "        ratings.append(rating.text.replace(\"ratings\", \"\").strip())\n",
    "    except:\n",
    "        rating= \"None\"\n",
    "        ratings.append(rating)\n",
    "    try:\n",
    "        try:\n",
    "            Modell = driver.find_element_by_xpath('//dt[contains(text(),\"Model Name\")]/following-sibling::dd[1]')\n",
    "        except:\n",
    "            Modell = driver.find_element_by_xpath('//dt[contains(text(),\"Model Number\")]/following-sibling::dd[1]')\n",
    "\n",
    "        Models.append(Modell.text.strip())\n",
    "    except:\n",
    "        Models.append(\"None\")\n",
    "\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29377f",
   "metadata": {},
   "source": [
    "### 5- Create csv file and fill it with values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8510e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Zip_longest to make the columns in the right position in excel\n",
    "file_list =[brands,Models,Prices,Description,links,colors,rams,storages,fulfillings,batteries,screen_sizes,rating_avgs,ratings]\n",
    "exported = zip_longest(*file_list)\n",
    "\n",
    "# Create csv file and fill it with values\n",
    "with open(\"F:\\mobiles_souq.csv\",\"w\", newline='',encoding='utf8') as myfile:\n",
    "    wr=csv.writer(myfile)\n",
    "    wr.writerow([\"Brand\",\"Model\",\"Price\",\"Description\",\"URL\",\"Color\",\"RAM\",\"Storage\",\"Shipping\",\"Battery\",\"Screen\",\"Rating\",\"Rating_count\"])\n",
    "    wr.writerows(exported)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
